# Stream computing overview

EnOS stream computing targets to meeting the real-time processing requirements.

EnOS stream computing service is built on Apache Spark™ Streaming. Based on the Apache Spark™ Streaming’s capabilities and customization based on these capabilities, EnOS stream computing offers high scalability, high throughput, and high fault tolerance.

The stream computing service provides access to the abstract computing models of user devices and sites. You can invoke your codes through the SDKs/APIs provided by EnOS for flexible customization based on your business needs.

## What is data stream?

In a broad sense, the generation of all data can be viewed as a series of discrete events that occur. When these discrete events are viewed in the dimension of time axis, an event stream / data stream is formed, and the data stream is generated from these **endless event streams**. Both offline data and data streams are usually sent in the form of data records. Unlike traditional offline data, data stream refers to data **generated continuously** by more data sources, but the size of data stream is generally smaller than offline data. Common data stream sources include telemetry data from the equipment and instruments connected in a data center, , and log files generated by mobile or Web applications

## What is stream computing?

In general, stream computing has the following characteristics

**Real-time and unbounded data streams**

  The computation faced by the engine is real-time and streaming, and the data
  streams are subscribed and consumed by stream computing in chronological order.
  The data is persisted and continuously collected. Thus, for streaming systems,
  the data is real-time and is not terminated, that is, unbounded.

**Continuous and efficient computing**

  Stream computing is "event triggered", and the trigger is the abovementioned
  unbounded data stream. Once new data stream is entered into computing system,
  the system immediately initiates and performs a computing task. Therefore, the
  entire stream computing is a continuous process.

**Streaming and real-time data integration**

  The result of streaming computing triggered by a data stream can be written
  directly into the destination data storage, for example, the report data may be
  written directly into relational database (RDS) for report rendering. Therefore,
  the computing results of a data stream can be continuously written to a
  destination data storage as a stream.

## Key Concepts of EnOS Streaming Computing

  The following key concepts are involved in the stream computing process:

  -   **Batch Size** – Apache Spark™ Streaming is a stream computing engine based
      on micro-batch model and processes data at the interval of batch size, which
      determines how often a stream computing task gets the data

  -   **Calculation Frequency** – Calculation frequency is predefined at EnOS
      Cloud level

  -   **Point Calculator** – Abstraction of raw data acquisition points and
      user-defined computation points

  -   **Device Calculator** – Calculation is based on device. For example, the
      device calculator can compute average wind speed of a specific interval
      based on the data of original wind speed measurement point.

  -   **Site Calculator** – Calculation is based on site, where a site is a
      logical concept which indicates a collection of multiple devices. For
      example, a collection of 10 turbines. The site calculator can compute
      site-level data, such as the total power generation for the 10 turbines of
      the logical site.

  -   **Virtual Calculator** – For logical sites, some acquisition points may be
      inconvenient to map to “any physical” devices, or some statistical points
      may be computed based on the sites and stored in a virtual device

  -   **Virtual Point** – Provided in the SDK for stream computing, used for
      representing the computation points of users

## Data Processing Flow of Stream Computing

The data flow of stream computing in the EnOS is as follows:

1. Process of raw data

  Original acquisition points are sent to Kafka through the EnOS connection layer. The messages received are analysed by the stream computing process of acquisition points and are mapped into domain points. In this process, Site ID and other data of the device is added to the point information. The information is then output to the Redis real-time database. The data of each collecting point is also sent to Kafka at the same time.

2. Invocation of device-level computing packages

  In this step, the device calculator states are recorded, and the user-defined computing based on stream data is performed. The computing process subscribes to the messages previously output to Kafka, that is, gets the data from original acquisition points, maps the acquisition points to point calculators, and aggregates the point calculators under each device calculator.

  The device calculators will then traverse the loaded computing packages based on updated state of the acquisition points and verify permissions based on the information provided in computing packages. The points computed by users are returned to platform framework and output to Redis real-time database and Kafka.

3. Invocation of site-level computing packages

  For devices under the same logical site, the platform framework aggregates the devices under site calculator object. Similar to the device-level computing process, the user’s computing packages need to pass permission verification to trigger site-level computing. When the user or application passes the permission verification, the user or application can access all acquisition points under a site through the site calculator object.

4.  Output of computing

  The data from the stream module, flows into Redis and Kafka, and the downstream will continue to subscribe all data from Kafka and write them to time series database (TSDB) and Hadoop distributed file system (HDFS). By default, data of the last three months are reserved in TSDB to support real-time queries through EnOS API, and the data in HDFS is used as the data source for offline data processing and further processing and analysis.

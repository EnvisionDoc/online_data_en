# Stream computing overview

## Stream computing

With the increasing demand for high timeliness and operability of information in various business scenarios, the demand for real-time processing of big data also becomes increasingly urgent, which poses higher requirements for software systems. The traditional big data processing model separates data from time series by OLTP and OLAP, but it can't adapt to the more and more urgent demand for real-time data processing. EnOS stream computing platform is established in the context of meeting customer's real-time processing needs.
EnOS stream computing platform is a data stream processing engine built on Apache Spark™ Streaming. Based on Apache Spark™ Streaming’s capabilities and customization based on these capabilities, EnOS stream computing offers high scalability, high throughput, and high fault tolerance. Currently, the stream computing platform provides access to the abstract computing models of user devices and sites, and can invoke your codes based on the SDK / API provided by the platform for flexible business customization.

## Basic Concept

- What is data stream?

    In a broad sense, the generation of all data can be viewed as a series of discrete events that occur. When these discrete events are viewed in the dimension of time axis, an event stream / data stream is formed, and the data stream is generated from these **endless event streams**. Both offline data and data streams are usually sent in the form of data records. Unlike traditional offline data, data stream refers to data **generated continuously** by more data sources, but the size of data stream is generally smaller than offline data. Common data stream sources include telemetry data from the equipment and instruments connected in a data center, , and log files generated by mobile or Web applications

- What is stream computing?

    In general, stream computing has the following characteristics

    + Real-time and unbounded data streams

        The computation faced by stream computing is real-time and streaming, and the data streams are subscribed and consumed by stream computing in chronological order. And because of the persistence of data generation, data streams will be integrated into the stream computing system for a long time and continuously. For example, for click log streams of a website, the click log streams will be constantly generated and entered into the stream computing system as long as the website is not closed. Thus, for streaming systems, the data is real-time and is not terminated (unbounded).

    + Continuous and efficient computing

       stream computing is an "event triggered" mode of computation, and the trigger source is the abovementioned unbounded data stream. Once new data stream is entered into stream computing, the stream computing system immediately initiates and performs a computational task, so the entire stream computing is a continuous computation.

    + Streaming and real-time data integration

        The computation result of a streaming computation triggered by data stream may be written directly into destination data storage, for example, the computed report data may be written directly into RDS for report presentation. Therefore, the computation results of data stream can be continuously written to destination data storage like the data stream.

## Exclusive concepts of EnOS stream computing platform

- **batch size**
    Apache Spark ™ Streaming is a stream computing engine based on micro-batch model and processes the data at the time of batch size, which determines **how often a stream computing task** gets the data**
- **calc frequency**
    A user-defined computation is also **determined by the platform uniformly**, and the frequency of computing frequency will be customized based on the control of different devices in different fields in the future
- PointCal
    Memory abstraction types for raw data acquisition points and user-defined computation points
- **DeviceCal**
    For the memory abstraction type of an acquisition device, the device can be an inverter, a fan, or a household refrigerator. Each DeviceCal object contains two map<String, PointCal>: pointMap and calPointMap, of which, pointMap stores the original device acquisition points, and calPointMap stores user-defined computation points
- **SiteCal**
    Memory abstraction type of a logical site, which is a collection of devices and contains a map<String, DeviceCal>
- **VirtualDevice**
    For logical sites, some acquisition points may be inconvenient to map to “any physical” devices in different business scenarios, or some statistical points may be computed based on the sites and stored in a virtual device
- **VirtualPoint**
    Provided in the SDK for stream computing, used for representing the computation points of users


## Data processing flow of EnOS stream computing

- **Processing of raw data**
    Original acquisition points are uniformly sent to Kafka by the EnOS connection layer. The messages received are analyzed by the stream computing processing tasks of acquisition points and mapped into domain points. In this process, site ID and other information are added to the point information, and then output to **Redis real-time database**. The data of each collection point is also sent to **Kafka** at the same time.
- **Invocation of device-level computational packages**
    This step is responsible for **maintaining the DeviceCal state of device objects** and **invoking the stream computing task for user-defined computation**. This task will subscribe to the messages previously output to Kafka, that is, get the data from original acquisition points, map it to PointCal and aggregate it under each DeviceCal. Each DeviceCal object will traverse loaded computation packages based on the **data update state** of acquisition points and **verify permissions** based on the information provided in the computation packages. The invocation of the computation packages can be triggered only if you have access right to corresponding data. The points computed by users are returned to the platform framework and output to **Redis real-time database and Kafka**.
- **Invocation of site-level computation packages**
    For devices under the same logical site, the platform framework will aggregate them under one SiteCal object. Users’ computation packages also need to pass **permission verification** to trigger the computation of the packages. For users, their access to the SiteCal object can obtain all acquisition points under the current site, but there is still certain cost to aggregate the data of the whole site. It is not recommended that all the computations be placed in the computing interface of the site.
- **Data output**
    The data coming from the stream computing platform, will flow into Redis and Kafka, and the downstream will continue to subscribe all the data from Kafka and write them to TSDB(Time Series Database) and HDFS. Generally, only the data of last three months are reserved in TSDB to provide real-time detailed queries in EnOS API, and the data in HDFS will be used as a data source for offline data processing for further processing and analysis.
